%!TEX root = ../../main.tex

% \section{Background}
% \label{sec:background}
% In this section, we examine events on Twitter.
% First, we examine existing corpora with an emphasis on their use for the detection and analysis of events, and describe the issues involved with the creation of a corpora specifically for this purpose.
% Secondly, we discuss the definition of \emph{event}, the issues associated with past and present definitions, and suggest a new definition of \emph{event} which fits the characteristics of Twitter.
% Finally, we examine event detection on Twitter, and more precisely define the task of event detection.
% We examine the current state-of-the-art in event detection and explore current evaluation methodologies.

\section{Existing Twitter Corpora}
\label{collection:sec:background}

\begin{table}[hb]
	\centering

	\caption[A comparison of the different Twitter corpora available prior to Events 2012 corpus.]{A comparison of the different Twitter corpora available prior to this collection. Values marked with * are estimates as exact numbers are not given. A question mark (?) indicates that the number of events is not clear.}
	\label{table:collectionsCompared}

	\begin{tabulary}{\textwidth}{lccccc}

	\toprule
	\textbf{Collection} & \textbf{Period} & \textbf{Tweets} & \textbf{Event based} & \textbf{Events} & \textbf{Unbiased} \\
	\midrule

	\cite{McCreadie:2012:BRT:2348283.2348495} & 14 days & 16M & No & - & - \\
	\cite{Becker:2012:ICP:2124295.2124360} & 28 days* & 2.6M & Yes & ? & No \\
	\cite{Petrovic:2012:UPI:2382029.2382072} & 75 days* & 50M & Yes & 27 & No \\
	\textbf{This Work} 	& 28 days & 120M & Yes & 506 & Yes \\

	\bottomrule
	\end{tabulary}

\end{table}

\label{sec:corproa}
In this section, we examine publicly available Twitter corpora, paying particular attention to their suitability for the evaluation of event-based systems and analysis.
We also discuss some of the challenges associated with the creation of a Twitter-sized corpus.

TREC ran the Microblog Track in 2011 with an ad-hoc retrieval task, and again in 2012 with ad-hoc retrieval and filtering tasks.
The Tweets2011 corpus~\cite{McCreadie:2012:BRT:2348283.2348495} was used both years, with new relevance judgements being generated each year.
The collection was the first publicly available large-scale Twitter corpus, containing 16 million tweets which cover a period of 2 weeks.
However, the corpus contains tweets in all languages and only around 4 million tweets remain after non-English tweets are removed.
Furthermore, the corpus is designed specifically for ad-hoc retrieval, and as such, the topics and relevance judgements are unsuitable for event-based analysis.
The TREC Microblog Track also ran in 2013, however the track moved to an experimental track-as-a-service approach, where the corpus was hosted by TREC and participants had to be queried using an API.  Once again, the set of topics used were designed specifically for ad-hoc retrieval, making them unsuitable for event-based analysis.

\cite{Becker:2012:ICP:2124295.2124360} produced what we believe was the first Twitter collection of events, however it only contains tweets posted by users in New York.
This clearly introduces geographical bias and restricts the type of events available.
The collection itself is also relatively tiny, containing only 2.6 million tweets.

\cite{Petrovic:2012:UPI:2382029.2382072} created a corpus aimed at First Story Detection, and while their collection contains a relatively high 50 million tweets from the beginning of July until mid-September 2011, they identified only 27 events.
This means that large scale comparisons are difficult as there is not a large sample of events (less than 1 event per day) and failure to detect only a small number of these could result in unsubstantiated and misleading results.

Although these collections have been made available, albeit in a limited fashion, none appear suitable for the analysis of events and comparison of event detection approaches.
The collection produced by~\citeauthor{Becker:2012:ICP:2124295.2124360} is simply too small to be of practical use for event detection, while the collection created by~\citeauthor{Petrovic:2012:UPI:2382029.2382072} covers too few events for a fair comparison to be made.
One reason for the lack of comparative corpora may be the difficulty and expense of creating one.
A reasonable sized Twitter corpus will contain tens of millions of documents -- performing a manual search on corpus of that magnitude is simply impossible.
To overcome this,~\citeauthor{Petrovic:2012:UPI:2382029.2382072} used a procedure similar to NIST, where expert annotators (primarily the authors of the paper) read the description of an event and used keywords to search for relevant documents.
However, this approach means that events (i) must be carefully identified in advance (potentially introducing bias) (ii) annotation requires expensive and slow experts, and (iii) it does not scale well past a certain size (\citeauthor{Petrovic:2012:UPI:2382029.2382072} were only able to create judgements for 27 events). This demonstrates the need for a methodology of creating unbiased large-scale and real-world corpora which can be used for the comparison of event detection techniques.