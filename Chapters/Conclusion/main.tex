%!TEX root = ../../main.tex

\chapter{Conclusions and Future Work}
\label{chapter:Conclusion}
We conclude with a summary of each chapter and detail their main contributions. We then examine our findings in relation to the research questions set out in chapter \ref{chapter:introduction}. Finally, we describe future areas and directions of research.

In chapter \ref{chapter:background} we described the background information necessary to understand this thesis. We gave an overview of Information Retrieval, described the Topic Detection and Tracking project, and summarised the most relevant literature.

In chapter \ref{chapter:collection} we described the creation of the first large-scale corpus for the evaluation of event detection approaches on Twitter.
We  proposed a new and refined definition of `event' for event detection on Twitter.
We detailed the approaches used to generate candidate events, and the crowdsourced methodology used to gather annotations and relevance judgements.

In chapter \ref{chapter:detection} we proposed a novel entity-based event detection approach for Twitter, that uses named entities to partition and efficiently cluster tweets.
We performed an in-depth evaluation of the detection approach using the Events 2012 corpus, which we believe was the first of its kind, and compared automated evaluation approaches with a crowdsourced evaluation. We described some of the issues that remain to be solved before automated evaluation can full replace crowdsourced evaluations of event detection approaches.

Finally, in chapter \ref{chapter:newsworthiness}, we proposed a method of scoring tweets based on their Newsworthiness.
We used heuristics to assign quality labels to tweets and learn term likelihood ratios, and calculate Newsworthiness scores.
We evaluated the classification and scoring accuracy using the Events 2012 corpus, and found it to be effective at classifying documents as Newsworthy or Noise.
We proposed a cluster Newsworthiness score that can be used as a feature for event detection, and evaluated it by filtering clusters produced using the entity-based clustering approach proposed in chapter \ref{chapter:detection}, finding that it can be used to increase precision even at small cluster sizes.

\section{Research Questions}
\textbf{RQ1: Can we develop a methodology that allows us to build a test collection for the evaluation of event detection approaches on Twitter?}\\
In chapter \ref{chapter:collection}, we answered this research question by creating a large-scale corpus with relevance judgements for the evaluation of event detection on Twitter.
Since the publication of \cite{McMinn2013} describing the corpus, more than 240 researchers and groups have registered to download the Events 2012 corpus, and it has been cited by more than 90 publications, and used in the development and evaluation of several event detection approaches for Twitter (including several PhD and Masters theses).
We used the collection we developed to evaluate our entity-based event detection approach, and our newsworthiness scoring technique, demonstrating that the collection is suitable for evaluating event detection approaches on Twitter.

\textbf{RQ2: Can entities (people, places, organizations) be used to improve real-world event detection in a streaming setting on Twitter?} \\
Chapter \ref{chapter:detection} describes our proposed entity-based, real-time event detection approach for Twitter.
Our entity-based approach partitions tweets based on the entities they contain to perform real-time clustering in an efficient manner, and uses a light-weight burst detection approach to identify unusual volumes of discussion around entities.
We found that it is possible to use entities to detect real-world event in a streaming setting on Twitter, and by evaluating this approach using the Events 2012 corpus, we found that it out-performed two state-of-the-art baselines.

\textbf{RQ3: Can event detection approaches be evaluated in a systematic and fair way?} \\
In chapter \ref{chapter:detection}, we used an automated evaluation methodology to evaluate our proposed event detection approach, and examined how these results compare to a crowdsourced evaluation.
We determined that although it is possible to automatically evaluate event detection approaches for Twitter, there remain a number of key challenges and issues that need to be addressed before automated evaluation can fully replace manual evaluation of event detection approaches.
\cite{Hasan17} surveyed real-time event detection techniques for Twitter in early 2017, and noted that the Events 2012 corpus remained the only corpus for the evaluation of event detection approaches on Twitter, suggesting that its continued use could help conduct fair performance comparisons between different event detection approaches \citep{Hasan17}.

\newpage
\textbf{RQ4: Can we determine the newsworthiness of an individual tweet from content alone?} \\
The Newsworthiness Scoring approach we developed in chapter \ref{chapter:newsworthiness} uses a set of heuristics to assign quality labels to tweets and learn term likelihood ratios to produce Newsworthiness Score for tweets in real-time.
We evaluated the scores as a classification and scoring task, and found that the approach is able to label Newsworthy and Noise tweets with a high degree of accuracy.
We then used the Newsworthiness Score to estimate cluster Newsworthiness as a feature for event detection.
We used the entity-based clustering approach proposed in chapter \ref{chapter:detection}, but filtered out clusters with low newsworthiness scores, resulting in extremely high precision with very few tweets.

\section{Future Work}
This thesis makes a number of contributions to the topic of event detection on Twitter.
We have build upon decades of previous work and made a number of proposals that improve upon existing approaches, enabling the creation of a test collection and improvements to event detection approaches for Twitter.
During this, we have identified a number of key areas where we believe future research could be focused and taken further.

\paragraph{Updated Collection} There are a number of opportunities to improve  test collections for the evaluation of event detection.
We note a number of areas where the Events 2012 corpus is lacking, such as a non-exhaustive list of events, and incomplete relevance judgements.
Whilst we do not believe these issues can ever be fully solved, improvements could be made by applying our methodology to additional event detection approaches and using these results to enrich the existing events and annotations.
Although we believe it may always be necessary to use crowdsourced evaluations to fully measure the effectiveness of an event detection approach, improvements to annotation coverage could help to improve performance estimates using the Events 2012 corpus.

\paragraph{New Collections}
The Events 2012 corpus is now over 6 years old.
Twitter has changed considerably in that time: its userbase has grown, and the length of tweets has increased from 140 to 280 characters.
We have proposed a methodology and demonstrated that it can be used to (relatively) quickly and easily build a test collection for Twitter.
The creation of a new test collection would allow us to better understand how changes to Twitter have affected the performance of event detection approaches, and would enable a more throughout evaluation by comparing performance across 2 or more datasets.


\paragraph{Name entity recognition} In chapter \ref{chapter:detection}, we argue that named entities play a strong role in describing events, and base our event detection approach on name entities.
We also rely heavily on them for event merging in chapter \ref{chapter:collection}.
However, named entity recognition on tweets is still a difficult task, and although performance of standard toolkits like the Stanford NER is adequate, there is much room for improved recognition, which could then feed improvements
in entity-based event detection approaches.
In their vein, a detailed analysis of how NER performance affects detection performance would be an interesting area of research that could give insight into the limits of entity-based event detection performance and a dependence on entities for detection limits detection approaches in areas such as First Story Detection.

\paragraph{Entity Linking and Disambiguation} blah

\paragraph{Deep learning} deep learning and related topics could offer vast improvements to event detection approaches in a number of ways which have yet to be properly explored.
Word Embedding, such as word2vec and GloVe, offer potentially huge improvements  to clustering performance on Twitter, which is often hampered by tweets short length and lexical mismatch.
Word Embedding could help to improve similarity measurements

\paragraph{Images and Multimedia}

\paragraph{Evaluation Improvements}

\paragraph{Summerization and Visualization} of events such as temporal summerization, or visualization.

\paragraph{Intelligent Feature} The Newsworthiness Score we developed shows promise