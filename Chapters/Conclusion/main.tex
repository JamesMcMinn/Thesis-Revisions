%!TEX root = ../../main.tex

\chapter{Conclusions and Future Work}
\label{chapter:Conclusion}
We conclude with a summary of each chapter and detail their main contributions. We then examine our findings in relation to the research questions set out in chapter \ref{chapter:introduction}. Finally, we describe future areas and directions of research.

In chapter \ref{chapter:background} we described the background information necessary to understand this thesis. We gave an overview of Information Retrieval, described the Topic Detection and Tracking project, and summarised the most relevant literature.

In chapter \ref{chapter:collection} we described the creation of the first large-scale corpus for the evaluation of event detection approaches on Twitter.
We  proposed a new and refined definition of `event' for event detection on Twitter.
We detailed the approaches used to generate candidate events, and the crowdsourced methodology used to gather annotations and relevance judgements.

In chapter \ref{chapter:detection} we proposed a novel entity-based event detection approach for Twitter, that uses named entities to partition and efficiently cluster tweets.
We performed an in-depth evaluation of the detection approach using the Events 2012 corpus, which we believe was the first of its kind, and compared automated evaluation approaches with a crowdsourced evaluation. We described some of the issues that remain to be solved before automated evaluation can full replace crowdsourced evaluations of event detection approaches.

Finally, in chapter \ref{chapter:newsworthiness}, we proposed a method of scoring tweets based on their Newsworthiness.
We used heuristics to assign quality labels to tweets and learn term likelihood ratios, and calculate Newsworthiness scores.
We evaluated the classification and scoring accuracy using the Events 2012 corpus, and found it to be effective at classifying documents as Newsworthy or Noise.
We proposed a cluster Newsworthiness score that can be used as a feature for event detection, and evaluated it by filtering clusters produced using the entity-based clustering approach proposed in chapter \ref{chapter:detection}, finding that it can be used to increase precision even at small cluster sizes.

\section{Research Questions}
\textbf{RQ1: Can we develop a methodology that allows us to build a test collection for the evaluation of event detection approaches on Twitter?}\\
In chapter \ref{chapter:collection}, we answered this research question by creating a large-scale corpus with relevance judgements for the evaluation of event detection on Twitter.
Since the publication of \cite{McMinn2013} describing the corpus, more than 240 researchers and groups have registered to download the Events 2012 corpus, and it has been cited by more than 90 publications, and used in the development and evaluation of several event detection approaches for Twitter (including several PhD and Masters theses).
We used the collection we developed to evaluate our entity-based event detection approach, and our newsworthiness scoring technique, demonstrating that the collection is suitable for evaluating event detection approaches on Twitter.

\textbf{RQ2: Can entities (people, places, organizations) be used to improve real-world event detection in a streaming setting on Twitter?} \\
Chapter \ref{chapter:detection} describes our proposed entity-based, real-time event detection approach for Twitter.
Our entity-based approach partitions tweets based on the entities they contain to perform real-time clustering in an efficient manner, and uses a light-weight burst detection approach to identify unusual volumes of discussion around entities.
We found that it is possible to use entities to detect real-world event in a streaming setting on Twitter, and by evaluating this approach using the Events 2012 corpus, we found that it out-performed two state-of-the-art baselines.

\textbf{RQ3: Can event detection approaches be evaluated in a systematic and fair way?} \\
In chapter \ref{chapter:detection}, we used an automated evaluation methodology to evaluate our proposed event detection approach, and examined how these results compare to a crowdsourced evaluation.
We determined that although it is possible to automatically evaluate event detection approaches for Twitter, there remain a number of key challenges and issues that need to be addressed before automated evaluation can fully replace manual evaluation of event detection approaches.
\cite{Hasan17} surveyed real-time event detection techniques for Twitter in early 2017, and noted that the Events 2012 corpus remained the only corpus for the evaluation of event detection approaches on Twitter, suggesting that its continued use could help conduct fair performance comparisons between different event detection approaches \citep{Hasan17}.

\newpage
\textbf{RQ4: Can we determine the newsworthiness of an individual tweet from content alone?} \\
The Newsworthiness Scoring approach we developed in chapter \ref{chapter:newsworthiness} uses a set of heuristics to assign quality labels to tweets and learn term likelihood ratios to produce Newsworthiness Score for tweets in real-time.
We evaluated the scores as a classification and scoring task, and found that the approach is able to label Newsworthy and Noise tweets with a high degree of accuracy.
We then used the Newsworthiness Score to estimate cluster Newsworthiness as a feature for event detection.
We used the entity-based clustering approach proposed in chapter \ref{chapter:detection}, but filtered out clusters with low newsworthiness scores, resulting in extremely high precision with very few tweets.

\section{Future Work}
This thesis makes a number of contributions to the topic of event detection on Twitter.
We have build upon decades of previous work and made a number of proposals that improve upon existing approaches, enabling the creation of a test collection and improvements to event detection approaches for Twitter.
During this, we have identified a number of key areas where we believe future research could be focused and taken further.

\subsubsection{An Updated Collection} There are a number of opportunities to improve  test collections for the evaluation of event detection.
We note a number of areas where the Events 2012 corpus is lacking, such as a non-exhaustive list of events, and incomplete relevance judgements.
Whilst we do not believe these issues can ever be fully solved, improvements could be made by applying our methodology to additional event detection approaches and using these results to enrich the existing events and annotations.
Although we believe it may always be necessary to use crowdsourced evaluations to fully measure the effectiveness of an event detection approach, improvements to annotation coverage could help to improve performance estimates using the Events 2012 corpus.

\subsubsection{New Collections}
The Events 2012 corpus is now over 6 years old.
Twitter has changed considerably in that time: its userbase has grown, and the length of tweets has increased from 140 to 280 characters.
We have proposed a methodology and demonstrated that it can be used to (relatively) quickly and easily build a test collection for Twitter.
The creation of new test collections would allow us to better understand how changes to Twitter have affected the performance of event detection approaches, and would enable a more throughout evaluation by comparing performance across 2 or more datasets.


\subsubsection{Name Entity Recognition}
In chapter \ref{chapter:detection}, we argue that named entities play a strong role in describing events, and base our event detection approach on name entities.
We also rely heavily on them for event merging in chapter \ref{chapter:collection}.
However, named entity recognition on tweets is still a difficult task, and although performance of standard toolkits like the Stanford NER is adequate, there is much room for improved recognition, which could then feed improvements
in entity-based event detection approaches.
In this vein, a detailed analysis of how NER performance affects detection performance would be an interesting area of research that could give insight into the limits of entity-based event detection performance and a dependence on entities for detection limits detection approaches in areas such as First Story Detection.

\subsubsection{Entity Linking and Disambiguation}
The application of Entity Linking and more robust disambiguation techniques could improve performance in a number of ways, particularly for event detection approaches such as ours that rely heavily on named entities.
We found that using 3 entity classes (person, location or organization) offers some improvements over using a single entity class, and it is likely that better disambiguation techniques would yield even better results.
Improvements to entity linking could help in a number of areas.
Although the co-occurrence method we used worked reasonably well, there are clearly improvements that could be made.
The use of an ontology to automatically link entities could offer improvements in a number of areas, for example, by linking a CEO to a company, or a politician to their country.
If this information was known in advance, then links could be found between events even without explicit mentions.

\subsubsection{Supervised Learning}
Deep learning and other related topics could offer vast improvements to event detection approaches and have yet to be explored in depth.
Word Embeddings, such as word2vec \citep{mikolov2013distributed} or GloVe \citep{pennington2014glove}, offer potential improvements  to clustering performance through improved similarity measurements and could offer a solution to issues such as lexical mismatch and the use of slang or abbreviations.

User classification, for example to identify good and reliable information sources, could help to improve the detection of smaller events by reducing the volume of tweets required before a decision can be made.
It would be interesting to examine how different types of user could be leveraged to improve detection.
Journalists, for example, may be useful for the detection of political or business news, however for unexpected events, it may be necessary to quickly identify reliable eye-witnesses and sources who are physically close to the event as they are likely to have the most up-to-date and correct information.
A supervised approach may prove to be effective here at discovering these users quickly.

Supervised approaches could also prove useful for identifying things such as fake news, or the manipulation of news by state actors -- something that is becoming an increasingly important as social media plays a more important role in people's voting decisions.


\subsubsection{Scoring Features}
The majority of event detection approaches still rely on basic tweet or user volume for cluster ranking and to perform filtering.
However, basic features like these ignore many of the benefits of event detection on Twitter, such as the ability to detect breaking news events before they have been widely reported (and thus have only a very small volume).
The Newsworthiness Score we developed shows promise and is able to detect events with high precision from very few tweets, however this approach uses only content based features to determine newsworthiness and could be improved in a number of ways.
The heuristics used to select tweets and train the models could be improved, or, more likely, replaced by supervised approaches.
Non-content features, such as the user's credibility, description and location could also be taken into consideration for scoring, perhaps even using the context of the event to improve scoring.
Of course, there is a wide range of novel features that could be explored, and as more training data is gathered, supervised approaches could be trained that will likely outperform current approaches to event detection.

\subsubsection{Evaluation Improvements}
The evaluation of event detection is still a very challenging area that would benefit from considerably work.
Determining the performance of an event detection approach is difficult without also performing crowdsourced evaluations.
Precision and Recall will be underestimated using the Events 2012 annotations due to incomplete relevance judgements and event coverage, however it is not yet clear if this underestimation will apply evenly to all event detection approaches or if it will affect some more than others.
An investigation into this would prove invaluable  and could pave a path forward.
As it stands, it is not clear if work should focus on increasing annotation coverage, developing a more robust evaluation methodology and set of metrics, or developing an entirely novel evaluation framework.
It is likely that modest improvements can be made simply by tweaking the methodology used by this work, with perhaps a new set of metrics to measure various different aspects of event detection, similar to the different evaluation methodologies used by the TDT project.
The development of an entirely new evaluation framework, whilst the most radical solution, is also likely to be the most successful.
A number of approaches could be taken, from automatically matching candidate events to news articles, to a fully crowdsourced evaluation methodology where only the differences between runs are evaluated.

